gpu_ids: [0,1,2,3]

paths:
  datasets_related: datasets_related
  dns_root: ../DNS3

light_conf:
  # optimizer
  lr: !!float 1e-3
  # scheduler
  # Dataset (.scp output paths; relative to repo). genscp.py will create these.
  train_mix_scp: "{datasets_related}/tr_mix.scp"
  train_ref_scp: 
    - "{datasets_related}/tr_s1.scp"
  # train_length_in_seconds: 9.0 # not implemented
  val_mix_scp: "{datasets_related}/cv_mix.scp"
  val_ref_scp: 
    - "{datasets_related}/cv_s1.scp"
  chunk_size_in_seconds: 10 # for training only; set None for full utterance (testing&validation)
  save_interval_epochs: 25
  sr: 16000
  # DataLoader
  batch_size: 36
  num_workers: 9

train:
  epochs: 200
  early_stop: true
  patience: 10
  limit_train_batches: 0.4
  distributed_backend: ddp #dp, ddp, ddp_cpu, ddp2
val:
  # val_check_interval: 1
  check_val_every_n_epoch: 1
  val_samples_to_save: 3

resume:
  path: 
  checkpoint: 
  load_from: None
# Input dataset directories for genscp.py to scan
data_dirs:
  train:
    mix: "{dns_root}/train_noisy"
    s1:  "{dns_root}/train_clean"
  val:
    mix: "{dns_root}/dev_noisy"
    s1:  "{dns_root}/dev_clean"
